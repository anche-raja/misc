#########################################################################
# CREATE DEPENDENCY RESOURCES/INFRASTRUCTURE
#########################################################################
# This creates a data object that contains some useful info, like account id which is used later in the code
data "aws_caller_identity" "current" {}

# This creates a data object that contains the current region name
data "aws_region" "current" {}

# This creates a source code repository
resource "aws_codecommit_repository" "codepipeline_source" {
  repository_name = "cc-repo"
  default_branch  = "master"
}
# This creates an s3 bucket, where various AWS services (as well as the user) can store data - for example codepipeline
resource "aws_s3_bucket" "artifacts_bucket" {
  bucket = join("", [var.base_name, "artifacts-bucket"])
}
# This creates an Elastic Container Registry - storage for container images
resource "aws_ecr_repository" "source_container_repository" {
  name = "container-repository"
  encryption_configuration {
    encryption_type = "AES256"
  }
}
# This is where we build the VPC using a standard AWS design
resource "aws_vpc" "vpc" {
  cidr_block           = "10.0.0.0/16"
  instance_tenancy     = "default"
  enable_dns_hostnames = true
  enable_dns_support   = true
  tags = {
    Name  = join("-", [var.base_name, "VPC"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_subnet" "private_subnet_a" {
  vpc_id            = aws_vpc.vpc.id
  cidr_block        = "10.0.0.0/20"
  availability_zone = "us-east-1a"
  tags = {
    Name  = join("-", [var.base_name, "private-subnet-a"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_subnet" "private_subnet_b" {
  vpc_id            = aws_vpc.vpc.id
  cidr_block        = "10.0.16.0/20"
  availability_zone = "us-east-1b"
  tags = {
    Name  = join("-", [var.base_name, "private-subnet-b"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_subnet" "public_subnet_a" {
  vpc_id            = aws_vpc.vpc.id
  cidr_block        = "10.0.128.0/20"
  availability_zone = "us-east-1a"
  tags = {
    Name  = join("-", [var.base_name, "public-subnet-a"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_subnet" "public_subnet_b" {
  vpc_id            = aws_vpc.vpc.id
  cidr_block        = "10.0.144.0/20"
  availability_zone = "us-east-1b"
  tags = {
    Name  = join("-", [var.base_name, "public-subnet-b"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_internet_gateway" "internet_gateway" {
  vpc_id = aws_vpc.vpc.id
  tags = {
    Name  = join("-", [var.base_name, "internet-gateway"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_route_table" "public_route_table" {
  vpc_id = aws_vpc.vpc.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.internet_gateway.id
  }
  tags = {
    Name  = join("-", [var.base_name, "public-route-table"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_route_table_association" "public_route_table_association_a" {
  subnet_id      = aws_subnet.public_subnet_a.id
  route_table_id = aws_route_table.public_route_table.id
}
resource "aws_route_table_association" "public_route_table_association_b" {
  subnet_id      = aws_subnet.public_subnet_b.id
  route_table_id = aws_route_table.public_route_table.id
}
resource "aws_route_table" "private_route_table_a" {
  vpc_id = aws_vpc.vpc.id
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.nat_gateway.id
  }
  tags = {
    Name  = join("-", [var.base_name, "private-route-table-a"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_route_table_association" "private_route_table_association_a" {
  subnet_id      = aws_subnet.private_subnet_a.id
  route_table_id = aws_route_table.private_route_table_a.id
}
resource "aws_route_table" "private_route_table_b" {
  vpc_id = aws_vpc.vpc.id
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.nat_gateway.id
  }
  tags = {
    Name  = join("-", [var.base_name, "private-route-table-b"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_route_table_association" "private_route_table_association_b" {
  subnet_id      = aws_subnet.private_subnet_b.id
  route_table_id = aws_route_table.private_route_table_b.id
}
resource "aws_eip" "nat_gateway_eip" {
  domain = "vpc"
  tags = {
    Name  = join("-", [var.base_name, "private-nat_gateway_eip"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_nat_gateway" "nat_gateway" {
  allocation_id = aws_eip.nat_gateway_eip.id
  subnet_id     = aws_subnet.public_subnet_a.id
  tags = {
    Name  = join("-", [var.base_name, "nat-gatway"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_vpc_endpoint" "s3_private_endpoint" {
  vpc_id       = aws_vpc.vpc.id
  service_name = "com.amazonaws.us-east-1.s3"
  tags = {
    Name  = join("-", [var.base_name, "s3-private-endpoint"])
    Notes = var.generic_tag_notes
  }
}
resource "aws_vpc_endpoint_route_table_association" "s3_private_endpoint_vpc_association_a" {
  route_table_id  = aws_route_table.private_route_table_a.id
  vpc_endpoint_id = aws_vpc_endpoint.s3_private_endpoint.id
}
resource "aws_vpc_endpoint_route_table_association" "s3_private_endpoint_vpc_association_b" {
  route_table_id  = aws_route_table.private_route_table_b.id
  vpc_endpoint_id = aws_vpc_endpoint.s3_private_endpoint.id
}
resource "aws_security_group" "allow_ssh_and_http_from_workspaces" {
  name        = "allow_ssh_http_from_workspaces"
  description = "Allow ssh traffic from the workspaces vpc only"
  vpc_id      = aws_vpc.vpc.id
  ingress {
    description = "SSH from load balancer"
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["3.83.200.219/32"]
  }
  ingress {
    description = "HTTP from workspaces VPC"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["3.83.200.219/32"]
  }
  ingress {
    description = "HTTPS from workspaces VPC"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["3.83.200.219/32"]
  }
  egress {
    description = "Allow all outbound traffic"
    from_port   = 0
    to_port     = 0
    protocol    = -1
    cidr_blocks = ["0.0.0.0/0"]
  }
}
resource "aws_security_group" "allow_traffic_from_workspaces" {
  name        = "allow_traffic_from_workspaces"
  description = "Allow web traffic from workspaces VPC."
  vpc_id      = aws_vpc.vpc.id
  ingress {
    description = "HTTP from workspaces VPC"
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["3.83.200.219/32"]
  }
  ingress {
    description = "HTTPS from workspaces VPC"
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["3.83.200.219/32"]
  }
  egress {
    description = "Allow all outbound traffic"
    from_port   = 0
    to_port     = 0
    protocol    = -1
    cidr_blocks = ["0.0.0.0/0"]
  }
}
resource "aws_security_group" "allow_traffic_from_load_balancer" {
  name        = "allow_traffic_from_load_balancer"
  description = "Allow web traffic from the load balancer (fowarded)"
  vpc_id      = aws_vpc.vpc.id
  ingress {
    description     = "HTTP from load balancer"
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    security_groups = ["${aws_security_group.allow_traffic_from_workspaces.id}"]
  }
  ingress {
    description     = "HTTPS from load balancer"
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    security_groups = ["${aws_security_group.allow_traffic_from_workspaces.id}"]
  }
  egress {
    description = "Allow all outbound traffic"
    from_port   = 0
    to_port     = 0
    protocol    = -1
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# This is where we pull in the latest AMI ID for Amazon Linux 2023
data "aws_ami" "amazon_linux_base_image" {
  most_recent = true
  filter {
    name   = "name"
    values = ["al2023-ami-*"]
  }
  filter {
    name   = "architecture"
    values = ["x86_64"]
  }
  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}
# This is where we create the role to be used by the server for getting to AWS resources
resource "aws_iam_role" "docker_server_role" {
  name = join("-", [var.base_name, "docker_server_role"])
  assume_role_policy = jsonencode({
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
  inline_policy {
    name = join("-", [var.base_name, "docker_server_role_ecr_full_access"])
    policy = jsonencode({
      Version = "2012-10-17"
      Statement = [
        {
          Sid      = "FullAccess"
          Action   = "*"
          Effect   = "Allow"
          Resource = "*"
        }
      ]
    })
  }
}

# This is where we create the instance profile
resource "aws_iam_instance_profile" "docker_server_profile" {
  name = join("-", [var.base_name, "docker_server_profile"])
  role = aws_iam_role.docker_server_role.name
}
# This is where we build the EC2 docker server/bastion host, which is used to issue docker commands and has access to talk to all AWS services
resource "aws_instance" "docker_server" {
  ami                         = data.aws_ami.amazon_linux_base_image.id
  iam_instance_profile        = aws_iam_instance_profile.docker_server_profile.name
  instance_type               = "t3.small"
  associate_public_ip_address = true
  key_name                    = var.ec2_key_name
  metadata_options {
    http_tokens = "required"
  }
  subnet_id       = aws_subnet.public_subnet_a.id
  security_groups = [aws_security_group.allow_ssh_and_http_from_workspaces.id]
  user_data       = <<EOF
#!/bin/bash
sudo yum update -y
sudo yum install nano -y
sudo yum install docker -y
sudo usermod -a -G docker ec2-user
sudo id ec2-user
sudo newgrp docker
sudo systemctl enable docker.service
sudo systemctl start docker.service
echo 'FROM httpd' > /tmp/Dockerfile
echo 'EXPOSE 80' >> /tmp/Dockerfile
cat /tmp/Dockerfile
aws ecr get-login-password --region ${data.aws_region.current.name} | docker login --username AWS --password-stdin ${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com
docker build -f /tmp/Dockerfile -t ${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com/container-repository:latest /tmp
docker images
IMAGE_ID=$(docker images -q ${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com/container-repository)
echo "Here is the image ID to be pushed:"
echo $IMAGE_ID
docker push ${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com/container-repository:latest
echo 'Script complete.  Exiting.'
EOF
}


#########################################################################
# CREATE ECS RESOURCES
#########################################################################
# This creates an Elastic Container Service cluster - used to run services on container infrastructure
resource "aws_ecs_cluster" "container_cluster" {
  name = join("-", [var.base_name, "container_cluster"])
}

# this creates a load balancer for the ECS cluster
resource "aws_lb" "ecs_load_balancer" {
  name               = "ecs-load-balancer"
  load_balancer_type = "application"
  subnets = [
    aws_subnet.public_subnet_a.id,
    aws_subnet.public_subnet_b.id
  ]
  security_groups = [aws_security_group.allow_traffic_from_workspaces.id]
}

# Create load balancer target group - blue
resource "aws_lb_target_group" "ecs_target_group_blue" {
  name        = "ecs-lb-target-group-blue"
  port        = 80
  protocol    = "HTTP"
  target_type = "ip"
  vpc_id      = aws_vpc.vpc.id
}

# Create load balancer target group - green
resource "aws_lb_target_group" "ecs_target_group_green" {
  name        = "ecs-lb-target-group-green"
  port        = 8080
  protocol    = "HTTP"
  target_type = "ip"
  vpc_id      = aws_vpc.vpc.id
}

# This is the load balancer listener
resource "aws_lb_listener" "ecs_lb_listener_http_80" {
  load_balancer_arn = aws_lb.ecs_load_balancer.arn
  port              = 80
  protocol          = "HTTP"
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.ecs_target_group_blue.arn
  }
}

# This is the load balancer listener
resource "aws_lb_listener" "ecs_lb_listener_http_8080" {
  load_balancer_arn = aws_lb.ecs_load_balancer.arn
  port              = 8080
  protocol          = "HTTP"
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.ecs_target_group_green.arn
  }
}

# This is where we create the role to be used by the container agent to deploy containers
resource "aws_iam_role" "container_agent_role" {
  name = "container_agent_role"
  assume_role_policy = jsonencode({
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "ecs-tasks.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
  inline_policy {
    name = "container_agent_policy"
    policy = jsonencode({
      Version = "2012-10-17"
      Statement = [
        {
          Sid = "FullAccess"
          Action = [
            "ecr:GetAuthorizationToken",
            "ecr:BatchCheckLayerAvailability",
            "ecr:GetDownloadUrlForLayer",
            "ecr:BatchGetImage",
            "logs:CreateLogGroup",
            "logs:CreateLogStream",
            "logs:PutLogEvents"
          ],
          Effect   = "Allow"
          Resource = "*"
        }
      ]
    })
  }
}

#  This is where we create the task definition for the containers to run in ECS
resource "aws_ecs_task_definition" "container_task_definition" {
  family                   = "container_service_task_family"
  cpu                      = 1024
  memory                   = 4096
  container_definitions    = <<TASK_DEFINITION
[
  {
      "name": "cloud-challenge",
      "image": "${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com/container-repository:latest",
      "portMappings": [
          {
              "name": "cloud-challenge-80-tcp",
              "containerPort": 80,
              "hostPort": 80,
              "protocol": "tcp",
              "appProtocol": "http"
          }
      ],
      "essential": true,
      "environment": [],
      "environmentFiles": [],
      "mountPoints": [],
      "volumesFrom": [],
      "ulimits": [],
      "logConfiguration": {
          "logDriver": "awslogs",
          "options": {
              "awslogs-create-group": "true",
              "awslogs-group": "/ecs/container_service_task_family",
              "awslogs-region": "us-east-1",
              "awslogs-stream-prefix": "ecs"
          },
          "secretOptions": []
      }
  }
]
TASK_DEFINITION
  task_role_arn            = aws_iam_role.container_agent_role.arn
  execution_role_arn       = aws_iam_role.container_agent_role.arn
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  runtime_platform {
    cpu_architecture        = "X86_64"
    operating_system_family = "LINUX"
  }
}

# This is where we create the role to be used by the container itself
resource "aws_iam_role" "container_role" {
  name = "container_role"
  assume_role_policy = jsonencode({
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "ecs.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
  inline_policy {
    name = "container_agent_policy"
    policy = jsonencode({
      Version = "2012-10-17"
      Statement = [
        {
          Sid      = "FullAccess" # This effectively allows the user to have the same level of access from the container as their admin SSO user/role
          Action   = "*"
          Effect   = "Allow"
          Resource = "*"
        }
      ]
    })
  }
}

resource "aws_ecs_service" "container_service" {
  depends_on      = [aws_nat_gateway.nat_gateway] # used to delay the creation of the ecs service until the image is available
  name            = "container_service"
  cluster         = aws_ecs_cluster.container_cluster.id
  task_definition = aws_ecs_task_definition.container_task_definition.arn
  desired_count   = 3
  launch_type     = "FARGATE"
  deployment_controller {
    type = "CODE_DEPLOY"
  }
  network_configuration {
    subnets = [
      aws_subnet.public_subnet_a.id,
      aws_subnet.public_subnet_b.id
    ]
    security_groups  = [aws_security_group.allow_traffic_from_load_balancer.id]
    assign_public_ip = true
  }
  load_balancer {
    container_name   = "cloud-challenge"
    container_port   = 80
    target_group_arn = aws_lb_target_group.ecs_target_group_blue.arn
  }
}

#########################################################################
# CREATE CODEBUILD RESOURCES
#########################################################################
data "aws_iam_policy" "codebuild_access" {
  arn = "arn:aws:iam::aws:policy/AWSCodeBuildAdminAccess"
}

data "aws_iam_policy" "codebuild_logs_access" {
  arn = "arn:aws:iam::aws:policy/CloudWatchLogsFullAccess"
}

data "aws_iam_policy" "codebuild_ecr_access" {
  arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess"
}

resource "aws_iam_role" "container_codebuild_role" {
  name = "codebuild_role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Sid    = "AllowCodebuildAssume"
      Principal = {
        Service = "codebuild.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "codebuild_access" {
  role       = aws_iam_role.container_codebuild_role.name
  policy_arn = data.aws_iam_policy.codebuild_access.arn
}

resource "aws_iam_role_policy_attachment" "codebuild_logs_access" {
  role       = aws_iam_role.container_codebuild_role.name
  policy_arn = data.aws_iam_policy.codebuild_logs_access.arn
}

resource "aws_iam_role_policy_attachment" "codebuild_ecr_access" {
  role       = aws_iam_role.container_codebuild_role.name
  policy_arn = data.aws_iam_policy.codebuild_ecr_access.arn
}

resource "aws_iam_role_policy_attachment" "codebuild_s3_access" {
  role       = aws_iam_role.container_codebuild_role.name
  policy_arn = data.aws_iam_policy.codepipeline_s3_access.arn
}

resource "aws_iam_role_policy_attachment" "codebuild_ecs_access" {
  role       = aws_iam_role.container_codebuild_role.name
  policy_arn = data.aws_iam_policy.ecs_access.arn
}

resource "aws_codebuild_project" "container_pipeline_codebuild_project" {
  name         = "container-pipeline-codebuild-project"
  service_role = aws_iam_role.container_codebuild_role.arn
  environment {
    compute_type    = "BUILD_GENERAL1_SMALL"
    image           = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"
    type            = "LINUX_CONTAINER"
    privileged_mode = true

    environment_variable {
      name  = "RESPOSITORY_URI"
      value = "${data.aws_caller_identity.current.account_id}.dkr.ecr.${data.aws_region.current.name}.amazonaws.com/container-repository:latest"
    }
    environment_variable {
      name  = "TASK_DEFINITION"
      value = aws_ecs_task_definition.container_task_definition.arn
    }
    environment_variable {
      name  = "CONTAINER_NAME"
      value = "cloud-challenge"
    }
    environment_variable {
      name  = "SUBNET_1"
      value = aws_subnet.public_subnet_a.id
    }
    environment_variable {
      name  = "SUBNET_2"
      value = aws_subnet.public_subnet_b.id
    }
    environment_variable {
      name  = "SECURITY_GROUP"
      value = aws_security_group.allow_traffic_from_load_balancer.id
    }
  }
  artifacts {
    type = "CODEPIPELINE"
  }
  source {
    type = "CODEPIPELINE"
  }
  project_visibility = "PRIVATE"

}

#########################################################################
# CREATE CODEDEPLOY RESOURCES
#########################################################################
data "aws_iam_policy" "codedeploy_access" {
  arn = "arn:aws:iam::aws:policy/AWSCodeDeployFullAccess"
}

data "aws_iam_policy" "load_balancer_access" {
  arn = "arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess"
}

data "aws_iam_policy" "ecs_access" {
  arn = "arn:aws:iam::aws:policy/AmazonECS_FullAccess"
}

resource "aws_iam_role" "container_codedeploy_role" {
  name = "codedeploy_role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Sid    = "AllowDeploybuildAssume"
      Principal = {
        Service = "codedeploy.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "codedeploy_access" {
  role       = aws_iam_role.container_codedeploy_role.name
  policy_arn = data.aws_iam_policy.codedeploy_access.arn
}

resource "aws_iam_role_policy_attachment" "load_balancer_access" {
  role       = aws_iam_role.container_codedeploy_role.name
  policy_arn = data.aws_iam_policy.load_balancer_access.arn
}

resource "aws_iam_role_policy_attachment" "ecs_access" {
  role       = aws_iam_role.container_codedeploy_role.name
  policy_arn = data.aws_iam_policy.ecs_access.arn
}

resource "aws_iam_role_policy_attachment" "codedeploy_s3_access" {
  role       = aws_iam_role.container_codedeploy_role.name
  policy_arn = data.aws_iam_policy.codepipeline_s3_access.arn
}

resource "aws_codedeploy_app" "codedeploy_container_application" {
  compute_platform = "ECS"
  name             = "codedeploy-container-application"
}

resource "aws_codedeploy_deployment_group" "container_deployment_group" {
  app_name               = aws_codedeploy_app.codedeploy_container_application.name
  deployment_group_name  = "ContainerDeploymentGroup"
  service_role_arn       = aws_iam_role.container_codedeploy_role.arn
  deployment_config_name = "CodeDeployDefault.ECSAllAtOnce"
  ecs_service {
    cluster_name = aws_ecs_cluster.container_cluster.name
    service_name = aws_ecs_service.container_service.name
  }
  deployment_style {
    deployment_option = "WITH_TRAFFIC_CONTROL"
    deployment_type   = "BLUE_GREEN"
  }
  load_balancer_info {
    target_group_pair_info {
      prod_traffic_route {
        listener_arns = [
          "${aws_lb_listener.ecs_lb_listener_http_80.arn}"
        ]
      }
      target_group {
        name = aws_lb_target_group.ecs_target_group_blue.name
      }
      target_group {
        name = aws_lb_target_group.ecs_target_group_green.name
      }
    }
  }
  blue_green_deployment_config {
    deployment_ready_option {
      action_on_timeout = "CONTINUE_DEPLOYMENT"
    }
    terminate_blue_instances_on_deployment_success {
      action                           = "TERMINATE"
      termination_wait_time_in_minutes = 5
    }
  }
}


#########################################################################
# CREATE CODEPIPELINE RESOURCES
#########################################################################
data "aws_iam_policy" "codepipeline_access" {
  arn = "arn:aws:iam::aws:policy/AWSCodePipeline_FullAccess"
}

data "aws_iam_policy" "codepipeline_codecommit_access" {
  arn = "arn:aws:iam::aws:policy/AWSCodeCommitFullAccess"
}

data "aws_iam_policy" "codepipeline_s3_access" {
  arn = "arn:aws:iam::aws:policy/AmazonS3FullAccess"
}

resource "aws_iam_role" "container_codepipeline_role" {
  name = "codepipeline_role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Sid    = "AllowCodepipelineAssume"
      Principal = {
        Service = "codepipeline.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "codepipeline_pipeline_access" {
  role       = aws_iam_role.container_codepipeline_role.name
  policy_arn = data.aws_iam_policy.codepipeline_access.arn
}

resource "aws_iam_role_policy_attachment" "codepipeline_codecommit_access" {
  role       = aws_iam_role.container_codepipeline_role.name
  policy_arn = data.aws_iam_policy.codepipeline_codecommit_access.arn
}

resource "aws_iam_role_policy_attachment" "codepipeline_s3_access" {
  role       = aws_iam_role.container_codepipeline_role.name
  policy_arn = data.aws_iam_policy.codepipeline_s3_access.arn
}

resource "aws_iam_role_policy_attachment" "codepipeline_codebuild_access" {
  role       = aws_iam_role.container_codepipeline_role.name
  policy_arn = data.aws_iam_policy.codebuild_access.arn
}

resource "aws_iam_role_policy_attachment" "codepipeline_codedeploy_access" {
  role       = aws_iam_role.container_codepipeline_role.name
  policy_arn = data.aws_iam_policy.codedeploy_access.arn
}

resource "aws_codepipeline" "container_pipeline" {
  name     = "container-pipeline"
  role_arn = aws_iam_role.container_codepipeline_role.arn
  artifact_store {
    location = aws_s3_bucket.artifacts_bucket.bucket
    type     = "S3"
  }
  stage {
    name = "Source"
    action {
      name             = "Download-Source"
      category         = "Source"
      owner            = "AWS"
      provider         = "CodeCommit"
      output_artifacts = ["SourceOutput"]
      configuration = {
        RepositoryName       = aws_codecommit_repository.codepipeline_source.repository_name
        BranchName           = "master"
        PollForSourceChanges = "true"
      }
      version = "1"
    }
  }
  stage {
    name = "Build"
    action {
      name             = "Container-Build-Action"
      category         = "Build"
      owner            = "AWS"
      provider         = "CodeBuild"
      input_artifacts  = ["SourceOutput"]
      output_artifacts = ["BuildOutput"]
      configuration = {
        ProjectName = aws_codebuild_project.container_pipeline_codebuild_project.id
      }
      version = "1"
    }
  }
  stage {
    name = "Deploy"
    action {
      name            = "Container-Deploy-Action"
      category        = "Deploy"
      owner           = "AWS"
      provider        = "CodeDeploy"
      input_artifacts = ["BuildOutput"]
      configuration = {
        ApplicationName     = aws_codedeploy_app.codedeploy_container_application.name
        DeploymentGroupName = aws_codedeploy_deployment_group.container_deployment_group.deployment_group_name
      }
      version = "1"
    }
  }
}


